{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](gru1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated Recurrent Units (GRU)\n",
    "\n",
    "## Overview\n",
    "Gated Recurrent Units (GRUs) are a type of Recurrent Neural Network (RNN) designed to capture dependencies in sequential data. They are similar to Long Short-Term Memory (LSTM) networks but with a simpler architecture, making them faster and more efficient.\n",
    "\n",
    "## Architecture of GRU\n",
    "\n",
    "A GRU unit consists of:\n",
    "\n",
    "1. **Hidden State (\\(h_t\\))**: Represents the current memory state of the network.\n",
    "2. **Gates**: GRUs have two main gates that control the flow of information:\n",
    "   - **Update Gate (\\(z_t\\))**: Determines how much of the past information needs to be passed along to the future.\n",
    "   - **Reset Gate (\\(r_t\\))**: Determines how much of the past information to forget.\n",
    "\n",
    "### Mathematical Representation\n",
    "\n",
    "1. **Update Gate**:\n",
    "   $$\n",
    "   z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t] + b_z)\n",
    "   $$\n",
    "\n",
    "2. **Reset Gate**:\n",
    "   $$\n",
    "   r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t] + b_r)\n",
    "   $$\n",
    "\n",
    "3. **Candidate Hidden State**:\n",
    "   $$\n",
    "   \\tilde{h}_t = \\tanh(W_h \\cdot [r_t * h_{t-1}, x_t] + b_h)\n",
    "   $$\n",
    "\n",
    "4. **Update Hidden State**:\n",
    "   $$\n",
    "   h_t = (1 - z_t) * h_{t-1} + z_t * \\tilde{h}_t\n",
    "   $$\n",
    "\n",
    "### Summary of GRU Equations\n",
    "- Update gate: \\( z_t \\)\n",
    "- Reset gate: \\( r_t \\)\n",
    "- Candidate hidden state: \\( \\tilde{h}_t \\)\n",
    "- Hidden state update: \\( h_t \\)\n",
    "\n",
    "## Use Cases of GRU\n",
    "\n",
    "GRUs are widely used in various applications, including:\n",
    "\n",
    "1. **Natural Language Processing (NLP)**:\n",
    "   - Language modeling\n",
    "   - Machine translation\n",
    "   - Sentiment analysis\n",
    "\n",
    "2. **Time Series Forecasting**:\n",
    "   - Predicting stock prices\n",
    "   - Weather forecasting\n",
    "\n",
    "3. **Speech Recognition**:\n",
    "   - Converting audio signals to text.\n",
    "\n",
    "4. **Music Generation**:\n",
    "   - Composing melodies based on previous notes.\n",
    "\n",
    "5. **Video Analysis**:\n",
    "   - Activity recognition in video streams.\n",
    "\n",
    "## Advantages of GRU\n",
    "\n",
    "- **Simplicity**: GRUs have a simpler architecture compared to LSTMs, making them faster to train.\n",
    "- **Fewer Parameters**: They require fewer parameters than LSTMs, which can reduce the risk of overfitting.\n",
    "\n",
    "## Disadvantages of GRU\n",
    "\n",
    "- **Less Control**: The simpler architecture may limit their ability to model complex dependencies compared to LSTMs in some cases.\n",
    "- **Performance Variability**: Depending on the task, GRUs may not always outperform LSTMs.\n",
    "\n",
    "## Implementation in TensorFlow/Keras\n",
    "\n",
    "Hereâ€™s a basic example of how to implement a GRU in TensorFlow/Keras:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(GRU(50, input_shape=(timesteps, features)))  # 50 GRU units\n",
    "model.add(Dense(1))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- basic rnn suffer from short term memory problem\n",
    "- a network which can remember important keyword <br>\n",
    "  - LSTM have long term memory and short term memory\n",
    "  - GRU combines long term and short term memory into its hidden state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM have 3 gates \n",
    "  - input output and forget\n",
    "- GRU have only 2 gates \n",
    "  - update gate (how much of past memory to retain)\n",
    "  - reset gate (how much of past memory to forget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
