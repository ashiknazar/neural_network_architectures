{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Networks (FNNs)\n",
    "\n",
    "#### Overview\n",
    "A feedforward neural network is one of the simplest types of artificial neural networks. It consists of an input layer, one or more hidden layers, and an output layer. The primary characteristic is that the information moves in one direction—from input to output—without any cycles or feedback connections.\n",
    "\n",
    "#### Structure\n",
    "\n",
    "1. **Input Layer**: Receives the input features.\n",
    "2. **Hidden Layers**: Intermediate layers that process inputs through neurons, applying weights and activation functions.\n",
    "3. **Output Layer**: Produces the final output, such as class labels for classification tasks.\n",
    "\n",
    "#### Mathematical Representation\n",
    "\n",
    "1. **Neuron Calculation**:\n",
    "   Each neuron in a layer calculates its output using the formula:\n",
    "   $$\n",
    "   z = w^T x + b\n",
    "   $$\n",
    "   - \\( z \\): Weighted sum of inputs\n",
    "   - \\( w \\): Weights\n",
    "   - \\( x \\): Input features\n",
    "   - \\( b \\): Bias term\n",
    "\n",
    "2. **Activation Function**:\n",
    "   The output of a neuron is passed through an activation function \\( f \\):\n",
    "   $$\n",
    "   a = f(z)\n",
    "   $$\n",
    "   Common activation functions include:\n",
    "   - **Sigmoid**: \n",
    "     $$\n",
    "     f(z) = \\frac{1}{1 + e^{-z}}\n",
    "     $$\n",
    "   - **ReLU (Rectified Linear Unit)**: \n",
    "     $$\n",
    "     f(z) = \\max(0, z)\n",
    "     $$\n",
    "   - **Tanh**: \n",
    "     $$\n",
    "     f(z) = \\tanh(z)\n",
    "     $$\n",
    "\n",
    "3. **Layer Output**:\n",
    "   The output of a layer can be represented as:\n",
    "   $$\n",
    "   a^{(l)} = f(W^{(l)} a^{(l-1)} + b^{(l)})\n",
    "   $$\n",
    "   where \\( l \\) indicates the layer number.\n",
    "\n",
    "4. **Loss Function**:\n",
    "   The network's performance is evaluated using a loss function, which quantifies the difference between predicted and actual values. Common loss functions include:\n",
    "   - **Mean Squared Error (MSE)** for regression:\n",
    "     $$\n",
    "     L(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "     $$\n",
    "   - **Cross-Entropy Loss** for classification:\n",
    "     $$\n",
    "     L(y, \\hat{y}) = -\\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)\n",
    "     $$\n",
    "\n",
    "#### Learning Process\n",
    "\n",
    "1. **Forward Propagation**:\n",
    "   - Input data is passed through the network, calculating activations at each layer to produce an output.\n",
    "\n",
    "2. **Backward Propagation**:\n",
    "   - The gradients of the loss function with respect to each weight are calculated using the chain rule.\n",
    "   - For each weight \\( w \\), the gradient is computed as:\n",
    "     $$\n",
    "     \\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial a^{(l)}} \\cdot \\frac{\\partial a^{(l)}}{\\partial z^{(l)}} \\cdot \\frac{\\partial z^{(l)}}{\\partial w}\n",
    "     $$\n",
    "\n",
    "3. **Weight Update**:\n",
    "   - Weights are updated using an optimization algorithm (e.g., Stochastic Gradient Descent, Adam):\n",
    "     $$\n",
    "     w = w - \\eta \\frac{\\partial L}{\\partial w}\n",
    "     $$\n",
    "   - Here, \\( \\eta \\) is the learning rate.\n",
    "\n",
    "#### Applications\n",
    "\n",
    "Feedforward neural networks are versatile and can be applied in various fields, including:\n",
    "\n",
    "1. **Image Classification**: Recognizing objects in images.\n",
    "2. **Regression Tasks**: Predicting continuous values (e.g., house prices).\n",
    "3. **Natural Language Processing**: Basic tasks like sentiment analysis.\n",
    "4. **Function Approximation**: Learning complex mappings between inputs and outputs.\n",
    "\n",
    "#### Advantages\n",
    "\n",
    "- **Simplicity**: Easy to implement and understand.\n",
    "- **Flexibility**: Can approximate any continuous function with sufficient hidden layers and neurons (Universal Approximation Theorem).\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "- **No Memory**: Cannot handle sequential data or temporal dependencies (compared to RNNs).\n",
    "- **Overfitting**: Can easily overfit with too many parameters, especially with limited data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Feedforward Neural Networks\n",
    "\n",
    "Feedforward neural networks (FNNs) are best suited for a variety of tasks, particularly when:\n",
    "\n",
    "1. **Data Structure is Fixed**: FNNs work well with fixed-size input data, such as vectors of features. If your input can be represented as a fixed-length array, an FNN is a suitable choice.\n",
    "\n",
    "2. **No Temporal Dependencies**: If your problem does not involve sequences or time-series data (e.g., no need for memory of past inputs), FNNs can efficiently process the input.\n",
    "\n",
    "3. **Simple Tasks**: For simpler tasks where relationships between inputs and outputs are relatively straightforward, FNNs can be effective.\n",
    "\n",
    "### Applications Suitable for FNNs\n",
    "\n",
    "While many applications can use various types of neural networks, some tasks are particularly well-suited for feedforward networks:\n",
    "\n",
    "1. **Tabular Data**: FNNs excel at processing structured data like spreadsheets or databases. Common applications include:\n",
    "   - **Credit scoring**: Predicting loan approval based on features like income, credit history, etc.\n",
    "   - **Medical diagnosis**: Classifying patients based on features such as age, symptoms, and test results.\n",
    "\n",
    "2. **Regression Problems**: Predicting continuous outputs based on input features, such as:\n",
    "   - **House price prediction**: Estimating property values based on features like location, size, and amenities.\n",
    "\n",
    "3. **Image Classification (Simpler Cases)**: For small, low-resolution images where the spatial hierarchy is less complex. However, CNNs are typically preferred for larger and more complex images.\n",
    "\n",
    "4. **Function Approximation**: FNNs can approximate mathematical functions given sufficient data, making them useful for tasks that require curve fitting.\n",
    "\n",
    "5. **Basic Natural Language Processing**: For simpler tasks like sentiment analysis or text classification where sequences are not critical, though more complex NLP tasks typically leverage RNNs or Transformers.\n",
    "\n",
    "### Limitations and Alternatives\n",
    "\n",
    "While FNNs are versatile, they may not be the best choice for:\n",
    "\n",
    "- **Sequential Data**: For tasks involving time-series data or sequences (like speech recognition), RNNs or LSTMs are more appropriate.\n",
    "- **Complex Image Processing**: For tasks requiring detailed feature extraction from images, CNNs are preferred.\n",
    "\n",
    "In summary, feedforward neural networks are effective for a wide range of applications, particularly when dealing with fixed-size, structured data and simpler relationships. If you have specific use cases in mind, I can help identify if FNNs are suitable or suggest alternatives!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](feed_for.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) * 10  # 100 samples, 1 feature\n",
    "y = 2.5 * X + np.random.randn(100, 1)  # Linear relationship with some noise\n",
    "\n",
    "# Visualize the data\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sample Data for Regression')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(1,)),             # Input layer\n",
    "    layers.Dense(10, activation='relu'),   # Hidden layer with 10 neurons\n",
    "    layers.Dense(1)                        # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 186.53271\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.3705 \n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.30682\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153.2834\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.4044\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.6327\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 122.6493\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.9668\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.9477\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107.4107\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.6226\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.3210\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101.3901\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100.5254\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84.9962 \n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.6865\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 82.3966\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 70.6049\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 68.8777\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.8724  \n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.7295\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57.3498\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41.8750\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 54.7397\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48.0164\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43.1160\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34.4578\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.1804\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36.1113\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27.16823\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.8628\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 21.3217  \n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0440\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.3509\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.2984\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 13.3492\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.4774\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8858\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.3049  \n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7004\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.3497\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.7774\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4475\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.1794\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 4.4513\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7912\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9333\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9274 \n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5494  \n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3395\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0381\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8445  \n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7575\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7024  \n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8214\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6382\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7254  \n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2704  \n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4257\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4057 \n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5651  \n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2995\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1124  \n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3435 \n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3430  \n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.39515\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3145\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1699  \n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1637\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3282\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3053\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3183\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2936  \n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2969\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1150  \n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2415 \n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1343\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3494\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1588\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3390\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0383  \n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.11653\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1137\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0038\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.450355\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1556\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0429  \n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1926\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 1.2976\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2059  \n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 1.0915\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1435  \n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2550  \n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2344\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2461\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1232\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0794\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2677\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1153  \n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3830 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1dc21d320c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0881 \n",
      "Mean Squared Error: 1.1561332941055298\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X, y)\n",
    "print(f\"Mean Squared Error: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Input: 0.00, Predicted Output: 1.25\n",
      "Input: 2.00, Predicted Output: 5.89\n",
      "Input: 4.00, Predicted Output: 10.44\n",
      "Input: 6.00, Predicted Output: 15.00\n",
      "Input: 8.00, Predicted Output: 19.55\n",
      "Input: 10.00, Predicted Output: 24.11\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "X_test = np.array([[0], [2], [4], [6], [8], [10]])\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print predictions\n",
    "for x_val, y_val in zip(X_test, y_pred):\n",
    "    print(f\"Input: {x_val[0]:.2f}, Predicted Output: {y_val[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175.0408 \n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156.8828\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.0463\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100.2388  \n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.9334 \n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42.9877\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.1808\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6454\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5590\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1439 \n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2291\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0498\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8626  \n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.96222\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9176 \n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9798\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0513\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9380\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8426 \n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0824  \n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8658\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8653\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8877\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7722\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8486\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9116 \n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8246\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0152\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9152\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8434\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0739\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8245\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9185\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8882  \n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9025\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8706\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8623  \n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8184 \n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8117 \n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8338\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.7326\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6954\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.9836\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 0.8986\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7998  \n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8557\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8169\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7916\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8769 \n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6302\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8414\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9497\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6306\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7217\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7920\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7951  \n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8556  \n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7981  \n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7919  \n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8961 \n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0480\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8989\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8657\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8551 \n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8482\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8035\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8248\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8481\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8167\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7016 \n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8787 \n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8746  \n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5990\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8552\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7463 \n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7278  \n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8033\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8987\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7779\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7593\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8248  \n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8325  \n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8626 \n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7637\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8499\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.76931\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7842\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8313\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8179 \n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8921  \n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7222\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7560\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9070\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0182\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7155  \n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8682  \n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7579\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8295\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.8735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1dc21f735c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(1,)),\n",
    "    layers.Dense(64, activation='relu'),  # Increase neurons in hidden layer\n",
    "    layers.Dense(64, activation='relu'),  # Add another hidden layer\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X, y, epochs=100, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7672 \n",
      "Mean Squared Error: 0.8064587116241455\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X, y)\n",
    "print(f\"Mean Squared Error: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Input: 0.00, Predicted Output: 0.32\n",
      "Input: 2.00, Predicted Output: 5.14\n",
      "Input: 4.00, Predicted Output: 10.05\n",
      "Input: 6.00, Predicted Output: 14.96\n",
      "Input: 8.00, Predicted Output: 19.88\n",
      "Input: 10.00, Predicted Output: 24.77\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "X_test = np.array([[0], [2], [4], [6], [8], [10]])\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print predictions\n",
    "for x_val, y_val in zip(X_test, y_pred):\n",
    "    print(f\"Input: {x_val[0]:.2f}, Predicted Output: {y_val[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 190.8431\n",
      "Epoch 2/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 179.8534\n",
      "Epoch 3/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 150.8038\n",
      "Epoch 4/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.9719\n",
      "Epoch 5/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 135.1346  \n",
      "Epoch 6/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136.1510 \n",
      "Epoch 7/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 128.8452\n",
      "Epoch 8/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 131.7222\n",
      "Epoch 9/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.9680 \n",
      "Epoch 10/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127.0054 \n",
      "Epoch 11/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127.7821\n",
      "Epoch 12/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.6796\n",
      "Epoch 13/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 129.8498\n",
      "Epoch 14/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128.5811\n",
      "Epoch 15/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.5880\n",
      "Epoch 16/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.8807\n",
      "Epoch 17/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.3734\n",
      "Epoch 18/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125.8502\n",
      "Epoch 19/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120.5470\n",
      "Epoch 20/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.0589 \n",
      "Epoch 21/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127.5349\n",
      "Epoch 22/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.0153\n",
      "Epoch 23/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 121.4564\n",
      "Epoch 24/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.2599 \n",
      "Epoch 25/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.1400\n",
      "Epoch 26/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.2037  \n",
      "Epoch 27/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 100.4373\n",
      "Epoch 28/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.8638\n",
      "Epoch 29/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 104.5948\n",
      "Epoch 30/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.6581 \n",
      "Epoch 31/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.0071\n",
      "Epoch 32/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108.9529 \n",
      "Epoch 33/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.8170 \n",
      "Epoch 34/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 104.6737\n",
      "Epoch 35/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 96.6948\n",
      "Epoch 36/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 89.9229\n",
      "Epoch 37/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.6301 \n",
      "Epoch 38/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 102.9371  \n",
      "Epoch 39/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 86.4041\n",
      "Epoch 40/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 96.0943  \n",
      "Epoch 41/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.1322\n",
      "Epoch 42/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 85.6865\n",
      "Epoch 43/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 94.1185\n",
      "Epoch 44/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82.6953\n",
      "Epoch 45/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.4091\n",
      "Epoch 46/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.1980 \n",
      "Epoch 47/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.0703 \n",
      "Epoch 48/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.1778 \n",
      "Epoch 49/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 81.6758\n",
      "Epoch 50/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 69.55770\n",
      "Epoch 51/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.2599  \n",
      "Epoch 52/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.8871\n",
      "Epoch 53/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 71.6332\n",
      "Epoch 54/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 58.7929\n",
      "Epoch 55/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.0685  \n",
      "Epoch 56/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8662\n",
      "Epoch 57/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.3961\n",
      "Epoch 58/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.7044\n",
      "Epoch 59/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 58.7649  \n",
      "Epoch 60/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.4022\n",
      "Epoch 61/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.0405\n",
      "Epoch 62/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.4017 \n",
      "Epoch 63/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52.0946\n",
      "Epoch 64/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.9058\n",
      "Epoch 65/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.2703\n",
      "Epoch 66/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.6430\n",
      "Epoch 67/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 39.1641 \n",
      "Epoch 68/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.3221\n",
      "Epoch 69/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.0400\n",
      "Epoch 70/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.4326\n",
      "Epoch 71/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.4183\n",
      "Epoch 72/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.7801\n",
      "Epoch 73/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.8692\n",
      "Epoch 74/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26.2125 \n",
      "Epoch 75/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.0789  \n",
      "Epoch 76/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.0163\n",
      "Epoch 77/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.6431\n",
      "Epoch 78/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.0342\n",
      "Epoch 79/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16.9930\n",
      "Epoch 80/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.0572\n",
      "Epoch 81/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.7712\n",
      "Epoch 82/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.8388\n",
      "Epoch 83/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.6514\n",
      "Epoch 84/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13.4457\n",
      "Epoch 85/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.8906\n",
      "Epoch 86/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.3976 \n",
      "Epoch 87/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.8684\n",
      "Epoch 88/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.4132\n",
      "Epoch 89/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.5248\n",
      "Epoch 90/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.0154\n",
      "Epoch 91/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3033 \n",
      "Epoch 92/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.3297\n",
      "Epoch 93/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.8010\n",
      "Epoch 94/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6707\n",
      "Epoch 95/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.9026\n",
      "Epoch 96/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6072\n",
      "Epoch 97/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5177\n",
      "Epoch 98/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6123\n",
      "Epoch 99/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6847\n",
      "Epoch 100/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4327  \n",
      "Epoch 101/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4164\n",
      "Epoch 102/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4070\n",
      "Epoch 103/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8727 \n",
      "Epoch 104/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2391 \n",
      "Epoch 105/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9079\n",
      "Epoch 106/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1725\n",
      "Epoch 107/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7144 \n",
      "Epoch 108/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5991\n",
      "Epoch 109/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4804 \n",
      "Epoch 110/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1301\n",
      "Epoch 111/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6385\n",
      "Epoch 112/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.24922\n",
      "Epoch 113/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3342\n",
      "Epoch 114/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6240\n",
      "Epoch 115/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7622\n",
      "Epoch 116/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1668  \n",
      "Epoch 117/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7538\n",
      "Epoch 118/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.98667\n",
      "Epoch 119/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7727\n",
      "Epoch 120/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9355\n",
      "Epoch 121/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5487 \n",
      "Epoch 122/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2006 \n",
      "Epoch 123/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8731\n",
      "Epoch 124/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0235\n",
      "Epoch 125/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1789\n",
      "Epoch 126/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6537 \n",
      "Epoch 127/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6487 \n",
      "Epoch 128/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0535\n",
      "Epoch 129/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4173\n",
      "Epoch 130/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4180\n",
      "Epoch 131/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9232\n",
      "Epoch 132/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7876\n",
      "Epoch 133/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8660\n",
      "Epoch 134/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5895\n",
      "Epoch 135/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0508\n",
      "Epoch 136/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6426 \n",
      "Epoch 137/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6699 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.1843  \n",
      "Mean Squared Error: 30.783275604248047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Input: 0.00, Predicted Output: 1.57\n",
      "Input: 2.00, Predicted Output: 5.13\n",
      "Input: 4.00, Predicted Output: 9.22\n",
      "Input: 6.00, Predicted Output: 10.43\n",
      "Input: 8.00, Predicted Output: 11.33\n",
      "Input: 10.00, Predicted Output: 12.58\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(1,)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Step 3: Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Step 4: Train the model\n",
    "model.fit(X, y, epochs=200, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "loss = model.evaluate(X, y)\n",
    "print(f\"Mean Squared Error: {loss}\")\n",
    "\n",
    "# Step 6: Make predictions\n",
    "X_test = np.array([[0], [2], [4], [6], [8], [10]])\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print predictions\n",
    "for x_val, y_val in zip(X_test, y_pred):\n",
    "    print(f\"Input: {x_val[0]:.2f}, Predicted Output: {y_val[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
